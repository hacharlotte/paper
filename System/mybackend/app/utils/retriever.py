from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

class AserRetriever:
    def __init__(self,
                 index_path="faiss_index/aser_causal.index",
                 text_path="faiss_index/aser_causal_texts.npy",
                 model_name="BAAI/bge-small-en-v1.5",  # å¯æ¢æˆä½ çš„æœ¬åœ°æ¨¡å‹è·¯å¾„
                 normalize=True):
        """
        åˆå§‹åŒ–æ£€ç´¢å™¨ï¼ŒåŠ è½½ç´¢å¼•ã€ä¸‰å…ƒç»„å’Œå‘é‡æ¨¡å‹
        """
        print("ğŸ“¥ åŠ è½½å¤–éƒ¨çŸ¥è¯†...")
        self.triples = np.load(text_path, allow_pickle=True).tolist()

        print("ğŸ§  åŠ è½½æ¨¡å‹ä¸­...")
        self.model = SentenceTransformer(model_name)

        print("ğŸ“¦ åŠ è½½å‘é‡ç´¢å¼•...")
        self.index = faiss.read_index(index_path)
        self.normalize = normalize

        # print(f"âœ… åˆå§‹åŒ–å®Œæˆï¼Œå…±è½½å…¥ {len(self.triples)} æ¡ä¸‰å…ƒç»„")
        print(f"âœ… åˆå§‹åŒ–å®Œæˆ")

    def retrieve(self, event_list, top_k=5):
        """
        è¾“å…¥ï¼šä¸€ç»„äº‹ä»¶ï¼ˆå­—ç¬¦ä¸²ï¼‰
        è¾“å‡ºï¼šæœ€ç›¸å…³çš„ Top-K ä¸‰å…ƒç»„
        """
        # å°†äº‹ä»¶æ‹¼æ¥æˆä¸€æ®µæ–‡æœ¬ï¼šæé«˜ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›
        query = ". ".join(event_list)
        query_vec = self.model.encode([query], normalize_embeddings=self.normalize).astype("float32")

        D, I = self.index.search(query_vec, top_k)
        return [self.triples[i] for i in I[0]], self.model
